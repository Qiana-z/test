{"messages": [
    {"role": "user", "content": "什么是SFT？"}, 
    {"role": "assistant", "content": "在自然语言处理（NLP）领域，Supervised Finetuning（SFT）是一种至关重要的技术手段，用来提升大模型在某一特定领域的表现。通过精细的策划和实施，SFT能够指导模型的学习过程，确保其学习成果与既定目标高度吻合。"}
]}
{"messages": [{"role": "user", "content": "什么时候需要SFT？"}, {"role": "assistant", "content": "通过 prompt engineering 无法解决或 prompt 中描述过于复杂时；对大模型输出内容有格式要求时，而模型仍有部分 case 不符合要求；期望通过 SFT 来减少 prompt 中的内容，加速线上推理的耗时。"}]}
{"messages": [{"role": "user", "content": "做SFT的前置依赖？"}, {"role": "assistant", "content": "一方面，把 prompt engineering 做到极致，通过优化 prompt 已经不能解决剩余的 badacse。另一方面，SFT 数据集中也依赖 prompt。因此，做 SFT 之前尽量把 prompt 工程做到最优。一开始不需要急着构造大量 SFT 数据集，可以先用少量数据（50条~100条）对模型做 SFT 后观察真实评估是否有收益。如果有收益，可以尝试以部分数据为种子数据集继续扩充，找到 scaling law。如果没有收益，那么再重新检查 SFT 数据集的质量"}]}
{"messages": [{"role": "user", "content": "SFT数据格式说明？"}, {"role": "assistant", "content": "请查看文档：https://www.volcengine.com/docs/82379/1099461"}]}
{"messages": [{"role": "user", "content": "SFT数据量级"}, {"role": "assistant", "content": "大模型中 SFT 的过程中，会学习 prompt 到 response 到映射关系，如果我们 SFT 的数据存在噪声（如错别字、错误格式、不符合预期输出的样本等），那么会对模型的训练过程造成比较严重的影响。因此，不可以一味去堆叠 SFT 的样本数量，样本的质量比数量更重要。针对不同场景下，数据量级的建议：文案生成，剧本创作，小说续写等生成类任务：2～3k；参考问答：2k ~ 1w；文本分类：1～3k，和类别数量以及任务难易度强相关，类别较多/任务较难的场景可能需要 1w 条以上。"}]}
{"messages": [{"role": "user", "content": "什么是混入预置数据？"}, {"role": "assistant", "content": "在模型精调页面，可以选择混入预置 SFT 数据，即在客户上传的 SFT 数据集的基础上，额外增加一部分比例的云雀模型基座训练时的 SFT 数据。"}]}
{"messages": [{"role": "user", "content": "为什么要混入预置数据？"}, {"role": "assistant", "content": "一定程度上缓解大模型在某个领域上 SFT 后，通用能力下降的问题。"}]}
{"messages": [{"role": "user", "content": "如何扩充SFT数据？"}, {"role": "assistant", "content": "我们经常会遇到一些场景，以用梗概生成小说这一场景为例，我们的候选库里有数以万计的小说，但是对应的每个章节的小说内容梗概却比较少，这种情况下我们可以利用云雀做数据增广，大致思路如下：\n我们构建一个根据小说全文生成小说梗概的模型：prompt 为待生成的小说梗概，用 Prompt engineering + Few Shots 的方式，用 Skylark2-pro-4k/32k 生成小说梗概，作为我们 SFT 数据补充的一部分\n\n查看生成的小说梗概是否与人工撰写的风格相似，如果不符合要求，则重复第一步，迭代 prompt 格式"}]}
{"messages": [{"role": "user", "content": "如何判断 SFT 数据质量好坏？"}, {"role": "assistant", "content": "badcase 的覆盖度：做 SFT 之前，我们肯定有一批 badcase。那么，我们做 SFT 的目的就是去解决这些 badcase。所以，要确保 SFT 数据集中对这些 badcase 有一定的覆盖度。这样，做完 SFT 才可能会有收益。\n\n正确性可以分两种情况，可以代码评估 / 需要人评：\n\n可以代码评估的情况：举一个例子，往往我们会遇到模型在一些任务上不遵循输出格式的问题。这时，我们会通过 SFT 来做对齐。假如说这里的格式是指 json 格式的话，那么我们可以通过代码 check 的方式，对 SFT 数据集做一遍检查。其他格式问题都可以通过这类代码校验的方式进行检查。那么这批 SFT 数据集好的质量就是正确格式的条数 / 总条数。\n\n需要人评的情况：从精调数据集中抽样 X 条（建议不少于50条）进行评估，假如有 Y 条是符合预期的，那么一定概率上这批 SFT 数据集好的质量是 Y/X。\n\n"}]}
{"messages": [{"role": "user", "content": "SFT训练方式如何选择？"}, {"role": "assistant", "content": "从参数更新范围的角度，目前方舟平台提供全量 SFT 和 lora 两种训练方式，具体区别如下：\n\n全量 SFT：即对预训练模型的所有参数进行更新，训练速度较慢，消耗机器资源较多。目前 pro 系列模型暂不支持。\n\nLoRA（Low-Rank Adaptation）：\n\n冻结了预训练模型的权重，并在每个 Transformer 块中注入可训练层，大大减少了可训练参数的数量。\n\n训练速度较快，消耗机器资源较少，价格比全量 SFT 更便宜。\n\n"}]}
{"messages": [{"role": "user", "content": "SFT训练参数如何选择？"}, {"role": "assistant", "content": "SFT 任务中，超参的选取会影响精调效果，下面逐一对部分重要参数进行解释：\n\nepoch：模型训练轮数，通常选择 2～5，可以根据验证集 loss 曲线来判断：如果训练集 loss 曲线下降，验证集 loss 曲线上升，则说明模型已经过拟合，此刻应该停止训练；如果训练集和验证集 loss 曲线均在缓慢下降，则说明模型还未收敛，可以继续训练。此外，对于文案生成，小说创作等生成类任务，由于某些上下文逻辑及风格不能通过 loss 体现，所以不应仅看 loss 来决定模型何时停止训练，按经验来说，通常生成类任务 epoch 数可以略微设置大一点，如 5～10 范围内。\n\nlearning rate：学习率，设置较大时会加速模型迭代，但是模型可能无法收敛到最优点；设置过小时会使得模型迭代较慢，可能陷入局部最优。按照经验来讲，LORA 训练选择 learning rate在 1e-4 ~ 2e-4，全量 SFT 选择learning rate 在 1e-5 ~ 2e-5即可。\n\nlora alpha 和 lora rank：alpha 参数将模型权重进行放缩，rank 决定了 lora 训练参数量的大小，我们推荐二者参数设置为同一值。通常来讲，对于较简单的任务，推荐设置 lora alpha 和 lora rank 64 或者 128；对于较复杂的任务，推荐设置 lora alpha 和 lora rank 为 256 或者 512。\n\n其中 Skylark2-pro-4k 1.1 版本中，由于更改了 lora 的部分逻辑，lora alpha 和 lora rank 可设置为上述推荐值的 1/4，learning rate 可设置为上述推荐值的 1/10 。\nnum warmup steps 和 warmup step rate：二者设置一个即可，通常不需要调整。当遇到模型在 SFT 训练开始时，loss 始终不降的问题时，可尝试调大 warmup step rate，再观察 loss 是否按预期下降。\n\nenable save models：保存最后多少个模型产物（checkpoint），对模型效果无影响。如在进行模型实验&调参时，可以调大此参数，来寻找最佳的模型 checkpoint。但是请注意，调大此参数会导致模型训练变慢（因为需要时间保存模型）\n\nbatchsize：通常设置为 1/2/4，搭配 epoch 和 learning rate 进行调整，batchsize 调大一倍时，要么 learning rate 调大一倍，要么 epoch 调大一倍。\n\n其余参数：通常保持默认参数即可\n\n"}]}
{"messages": [{"role": "user", "content": "SFT效果如何评估？"}, {"role": "assistant", "content": "有两类评估方式：1. 训练过程中观察 loss 指标；2. 发布服务后在真实评估集上评估。\n\nloss 指标：一般观察在训练集和验证集上的损失来评估模型精调的效果。\n\n真实评估集：发布服务后评估业务指标。\n\n"}]}
{"messages": [{"role": "user", "content": "如何构造 SFT 数据集？"}, {"role": "assistant", "content": "数据质量重要性大于数据数量。\n\n收集足够量的 SFT 数据集，清洗掉错误、无效冗余、有歧义的 case，因为这样的数据可能会导致做完 SFT 之后，影响整体效果。\n\n针对性地多收集一些模型反复出错的 badcase，洞察和分析找到共性后构造 SFT 数据集，并让 SFT 数据集的分布尽量接近 badcase 的分布，使得 SFT 数据集覆盖度足够广，能够最大程度解决掉 badcase。\n\n"}]}
{"messages": [{"role": "user", "content": "怎么加快调参效率？"}, {"role": "assistant", "content": "多存 ckpt、控制变量调参。\n\n尽量在精调时多训几个 epoch，多存几个 ckpt，这样在服务发布时，可以选择性的发布不同 step 的 ckpt 来看模型表象。\n\n尽量对于超参在不同阈值区间控制变量调参，找到调大或调小和指标的关系。\n\n"}]}
{"messages": [{"role": "user", "content": "SFT 过程 prompt 中 fewshots 按相关性采样的影响"}, {"role": "assistant", "content": "以文案生成任务举例，营销文案在不同渠道风格差异相差比较大，此时如果 SFT 数数据量较少，可能会导致LLM 无法细致地区分出来不同渠道的风格差异，在这种场景可以采取 few shots + SFT 的方式进行训练。具体思路如下：\n\n构造 SFT 数据时，假设某条数据的 response 为 push 场景的文案，那么在 few shots 的选取中，如果选取其他场景，如社媒，直邮等场景的文案作为 few shots 的示例，那么风格无法对齐，会对结果造成比较大的干扰。因此在选取 few shots 时，尽量选择同场景的数据作为示例。\n综上所述，在 SFT 数据量较少的情况下，第一步需要先找到场景在哪个维度上，response 分布的差异比较大，然后在构建 few shots SFT 数据时，尽量选取同个维度的优质下·数据作为 few shots 示例。"}]}
{"messages": [{"role": "user", "content": "SFT 数据集中 response 的多样性"}, {"role": "assistant", "content": "同样以文案生成任务举例，当我们希望同样的 prompt 生成出来的内容更多样时，我们可以：\n调大接口参数中 temperature、top_p 等参数，引入多样性。比如 temperature 和 top_p 都可以调整到1.0。\n\n我们可以尝试在 SFT 数据集中，构造同样的输入 prompt，多样性的 response 数据。经测试后，模型输出多样性指标得到提升。\n\n"}]}
